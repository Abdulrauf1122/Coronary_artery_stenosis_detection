{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdulrauf1122/Coronary_artery_stenosis_detection/blob/main/Stenosis_Detection_Faster_RCNN_Inception_ResNetV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8lO8PUXWmOY"
      },
      "source": [
        "# **Mounting Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0x5NN7-PJfyn"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!rm -rf /content/sample_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1_On7ooWhZ3"
      },
      "source": [
        "# **Cloning my_Repository**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGhGu-9qKMxd"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Abdulrauf1122/Coronary_artery_stenosis_detection.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Installing necessary libraries**"
      ],
      "metadata": {
        "id": "j1RysIfoc1ha"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-P3_oSyrKg6T"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "%cd /content\n",
        "\n",
        "!pip uninstall opencv-python opencv-contrib-python imgaug -y\n",
        "!pip install imgaug==0.2.5 opencv-python-headless==4.1.2.30 lvis\n",
        "\n",
        "!pip install tf-models-official==2.8 tensorflow-gpu==2.8 keras==2.8 tensorboard==2.8 tensorflow-estimator==2.8\n",
        "!pip install tensorflow.io\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!apt install --allow-change-held-packages libcudnn8=8.4.0.27-1+cuda11.1\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "!pip install -q pycocotools\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"Installed Tensorflow version >>> \", tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Downloading the TensorFlow Model Garden**"
      ],
      "metadata": {
        "id": "zKmEmb6Kc5eP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFsr9T_LKi7W"
      },
      "outputs": [],
      "source": [
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python /content/models/research/object_detection/builders/model_builder_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Protobuf Installation/Compilation**"
      ],
      "metadata": {
        "id": "ThZzIaPCdFc1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79ly4mMBKzAl"
      },
      "outputs": [],
      "source": [
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **COCO API installation**"
      ],
      "metadata": {
        "id": "ZUVrBoXZdKa4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqgk-qM4K8q-"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/cocodataset/cocoapi.git\n",
        "%cd cocoapi/PythonAPI\n",
        "!make\n",
        "%cp -r pycocotools /content/models/research"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test object detection API**"
      ],
      "metadata": {
        "id": "NAuKw8yAdUgb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OF0C0mXK-vt"
      },
      "outputs": [],
      "source": [
        "%cd /content/models/research\n",
        "%cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install .\n",
        "!python object_detection/builders/model_builder_tf2_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbJU1XOAWWOW"
      },
      "source": [
        "# **Downloading Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bX-QbGNfyMq0"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "import time\n",
        "\n",
        "%cd /content/\n",
        "st = time.time()\n",
        "q = input(\"Are you sure? Y/N :\")\n",
        "if q == 'Y':\n",
        "    !wget https://md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com/ydrm75xywg-1.zip\n",
        "    with zipfile.ZipFile('/content/ydrm75xywg-1.zip') as zf:\n",
        "        for member in tqdm(zf.infolist(), desc='Extracting preliminary'):\n",
        "            try:\n",
        "                zf.extract(member, \"/content/dataset\")\n",
        "            except zipfile.error as e:\n",
        "                pass\n",
        "    !rm /content/ydrm75xywg-1.zip\n",
        "    with zipfile.ZipFile('/content/dataset/ydrm75xywg-1/Stenosis detection.zip') as zf:\n",
        "        for member in tqdm(zf.infolist(), desc='Extracting final dataset'):\n",
        "            try:\n",
        "                zf.extract(member, \"/content/stenosis_dataset\")\n",
        "            except zipfile.error as e:\n",
        "                pass\n",
        "    print(\"Cleaning up after downlaod and extraction\")\n",
        "    !rm -rf /content/dataset\n",
        "    !rm -rf /content/stenosis_dataset/video_test\n",
        "    !rm -rf /content/stenosis_dataset/video_val\n",
        "    print(\"Download & extraction completed\")\n",
        "else:\n",
        "    print(\"Moving on ...\")\n",
        "\n",
        "et = time.time()\n",
        "elapsed_time = et - st\n",
        "print('\\nExecution time:', elapsed_time/60, ' minutes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPZ4VU1WW_nw"
      },
      "source": [
        "# **Creating folder structure**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKo5d5b2EbyX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "workspace_path = '/content/drive/MyDrive/workspace/'\n",
        "workspace_model_path = workspace_path + 'stenosis_detection_FRCNN/'\n",
        "annotation_path = workspace_model_path + 'annotations/'\n",
        "exported_model_path = workspace_model_path + 'exported-models/'\n",
        "images_path = workspace_model_path + 'images/'\n",
        "trained_model_path = workspace_model_path + 'trained_model/'\n",
        "pretrained_model_path = workspace_model_path + 'pre-trained-models/'\n",
        "\n",
        "try:\n",
        "    os.mkdir(workspace_path)\n",
        "    print(\"Created workspace\")\n",
        "except FileExistsError :\n",
        "    print(\"workspace directory already exists: creating rest of the structure inside workspace\")\n",
        "try:\n",
        "    os.mkdir(workspace_model_path)\n",
        "    os.mkdir(annotation_path)\n",
        "    os.mkdir(exported_model_path)\n",
        "    os.mkdir(images_path)\n",
        "    os.mkdir(trained_model_path)\n",
        "    os.mkdir(pretrained_model_path)\n",
        "    print(\"full directory structure creation done\")\n",
        "except FileExistsError :\n",
        "    print(\"directory structure already exists: Will be using existing directories\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYn_yGxkXa-k"
      },
      "source": [
        "# **Creating labelmap.pbtxt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMfAiPDDFA2o"
      },
      "outputs": [],
      "source": [
        "labels = [{'name':'Stenosis', 'id':1}]\n",
        "with open(annotation_path + \"label_map.pbtxt\", 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNbs0fMkXZZf"
      },
      "source": [
        "# **Partitioning the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67yY7G_2GRf0"
      },
      "outputs": [],
      "source": [
        "st = time.time()\n",
        "q = input(\"Are you sure? Y/N :\")\n",
        "if q == 'Y':\n",
        "    if os.path.isdir(\"/content/stenosis_dataset/dataset\"):\n",
        "        !rm -rf /content/drive/MyDrive/workspace/stenosis_detection_FRCNN/images/\n",
        "        os.mkdir(images_path)\n",
        "\n",
        "        !python /content/coronary-artery-stenosis-detection/partition_dataset.py -x -i /content/stenosis_dataset/dataset -o /content/drive/MyDrive/workspace/stenosis_detection_FRCNN/images -r 0.1\n",
        "\n",
        "        print(\"Dataset split into Train & Test\")\n",
        "        print(\"Cleaning up after partitioning dataset\")\n",
        "        !rm -rf /content/stenosis_dataset\n",
        "    else:\n",
        "      print(\"Dataset doesn't exists\")\n",
        "else:\n",
        "    print('Moving on ...')\n",
        "et = time.time()\n",
        "elapsed_time = et - st\n",
        "print('\\nExecution time:', elapsed_time/60 , 'minutes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3KbLaanZd1g"
      },
      "source": [
        "# **Generating TF records**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **train record**"
      ],
      "metadata": {
        "id": "kMSq9KDHeOGv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBqfHoM1aQF2"
      },
      "outputs": [],
      "source": [
        "st = time.time()\n",
        "q = input(\"Are you sure? Y/N :\")\n",
        "if q == 'Y':\n",
        "    !python /content/coronary-artery-stenosis-detection/generate_tfrecord.py -x /content/drive/MyDrive/workspace/stenosis_detection_FRCNN/images/train -l /content/drive/MyDrive/workspace/stenosis_detection_FRCNN/annotations/label_map.pbtxt -o /content/drive/MyDrive/workspace/stenosis_detection_FRCNN/annotations/train.record\n",
        "else:\n",
        "    print('Moving on ...')\n",
        "et = time.time()\n",
        "elapsed_time = et - st\n",
        "print('\\nGenerated train.record successfully')\n",
        "print('Execution time:', elapsed_time/60 , 'minutes')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **test record**"
      ],
      "metadata": {
        "id": "JDc0GvlgepHn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgxheItoMDmr"
      },
      "outputs": [],
      "source": [
        "st = time.time()\n",
        "q = input(\"Are you sure? Y/N :\")\n",
        "if q == 'Y':\n",
        "    !python /content/coronary-artery-stenosis-detection/generate_tfrecord.py -x /content/drive/MyDrive/workspace/stenosis_detection_FRCNN/images/test -l /content/drive/MyDrive/workspace/stenosis_detection_FRCNN/annotations/label_map.pbtxt -o /content/drive/MyDrive/workspace/stenosis_detection_FRCNN/annotations/test.record\n",
        "else:\n",
        "    print('Moving on ...')\n",
        "et = time.time()\n",
        "elapsed_time = et - st\n",
        "print('\\nGenerated train.record successfully')\n",
        "print('Execution time:', elapsed_time/60 , 'minutes')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Download & extract pretrained model**"
      ],
      "metadata": {
        "id": "M2bY23NneyvD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PssQ1V-QOWOI"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/workspace/stenosis_detection_FRCNN/pre-trained-models\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8.tar.gz\n",
        "!tar -xzvf /content/drive/MyDrive/workspace/stenosis_detection_FRCNN/pre-trained-models/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8.tar.gz\n",
        "!rm /content/drive/MyDrive/workspace/stenosis_detection_FRCNN/pre-trained-models/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8.tar.gz\n",
        "print(\"\\nDownload & extraction completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configure training pipeline**"
      ],
      "metadata": {
        "id": "E9HtriIqe4qF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtqNrWfkMJ_2"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_model_path = trained_model_path + \"my_FRCNN/\"\n",
        "CONFIG_PATH = my_model_path + \"pipeline.config\""
      ],
      "metadata": {
        "id": "vHaqT0FEfGZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    os.mkdir(my_model_path)\n",
        "except FileExistsError :\n",
        "    print(\"my FRCNN already exists\")\n",
        "!cp {\"/content/drive/MyDrive/workspace/stenosis_detection_FRCNN/pre-trained-models/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8/pipeline.config\"} {my_model_path}\n",
        "config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)"
      ],
      "metadata": {
        "id": "deGRZ-wkfKCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
        "CONFIG_PATH"
      ],
      "metadata": {
        "id": "vdheSrOkfP6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(CONFIG_PATH, \"r\") as f:\n",
        "    proto_str = f.read()\n",
        "    text_format.Merge(proto_str, pipeline_config)"
      ],
      "metadata": {
        "id": "WD1fuOxrfZRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_config.model.faster_rcnn.num_classes = 1\n",
        "pipeline_config.train_config.batch_size = 1\n",
        "pipeline_config.train_config.fine_tune_checkpoint = pretrained_model_path + \"faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8/checkpoint/ckpt-0\"\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_config.use_bfloat16 = False\n",
        "pipeline_config.train_input_reader.label_map_path= annotation_path + \"label_map.pbtxt\"\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [annotation_path + \"train.record\"]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = annotation_path + \"label_map.pbtxt\"\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [annotation_path + \"test.record\"]"
      ],
      "metadata": {
        "id": "53qSd7LNfc4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)\n",
        "with tf.io.gfile.GFile(CONFIG_PATH, \"wb\") as f:\n",
        "    f.write(config_text)"
      ],
      "metadata": {
        "id": "waOGxh5WfgDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "updated_config_path = my_model_path + \"pipeline.config\"\n",
        "updated_config = config_util.get_configs_from_pipeline_file(updated_config_path)\n",
        "updated_config"
      ],
      "metadata": {
        "id": "ssO5UAtnfikM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training the model**"
      ],
      "metadata": {
        "id": "xi4Iq6zkfosi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Configuring GPU**"
      ],
      "metadata": {
        "id": "Soh6SypqfuhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
        "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "gpus"
      ],
      "metadata": {
        "id": "wqssVkaYfrQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training model**"
      ],
      "metadata": {
        "id": "AC7hE4dSf2sD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py --model_dir=/content/drive/MyDrive/workspace/stenosis_detection_FRCNN/trained_model/my_FRCNN --pipeline_config_path=/content/drive/MyDrive/workspace/stenosis_detection_FRCNN/trained_model/my_FRCNN/pipeline.config --num_train_steps=20000"
      ],
      "metadata": {
        "id": "P8J7j3X6f5Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwstvunW8CUV"
      },
      "source": [
        "# **Evaluating the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qF4S4sbK8HX5"
      },
      "outputs": [],
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py --model_dir=/content/drive/MyDrive/workspace/stenosis_detection_FRCNN/trained_model/my_FRCNN --pipeline_config_path=/content/drive/MyDrive/workspace/stenosis_detection_FRCNN/trained_model/my_FRCNN/pipeline.config --checkpoint_dir=/content/drive/MyDrive/workspace/stenosis_detection_FRCNN/trained_model/my_FRCNN\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSmY3mXG5di_"
      },
      "source": [
        "# **Exporting model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4cNBOCyEgpFa"
      },
      "outputs": [],
      "source": [
        "os.mkdir(\"/content/drive/MyDrive/workspace/stenosis_detection_FRCNN/exported-models/my_model_20000\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aacpEYi-OeHY"
      },
      "outputs": [],
      "source": [
        "!python /content/models/research/object_detection/exporter_main_v2.py --input_type image_tensor --pipeline_config_path /content/drive/MyDrive/workspace/stenosis_detection_FRCNN/trained_model/my_FRCNN/pipeline.config --trained_checkpoint_dir /content/drive/MyDrive/workspace/stenosis_detection_FRCNN/trained_model/my_FRCNN --output_directory /content/drive/MyDrive/workspace/stenosis_detection_FRCNN/exported-models/my_model_20000"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inferencing trained model**"
      ],
      "metadata": {
        "id": "uzZ0j2hcMggg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXI43GKiOueh"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Object Detection (On Image) From TF2 Saved Model\n",
        "=====================================\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import argparse\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Enable GPU dynamic memory allocation\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "\n",
        "# PROVIDE PATH TO MODEL DIRECTORY\n",
        "PATH_TO_MODEL_DIR = '/content/drive/MyDrive/workspace/stenosis_detection_FRCNN/exported-models/my_model_20000'\n",
        "\n",
        "# PROVIDE PATH TO LABEL MAP\n",
        "PATH_TO_LABELS = '/content/drive/MyDrive/workspace/stenosis_detection_FRCNN/annotations/label_map.pbtxt'\n",
        "\n",
        "# PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n",
        "MIN_CONF_THRESH = float(0.80)\n",
        "\n",
        "# LOAD THE MODEL\n",
        "\n",
        "import time\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "PATH_TO_SAVED_MODEL = \"/content/drive/MyDrive/workspace/stenosis_detection_FRCNN/exported-models/my_model_20000/saved_model\"\n",
        "\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))\n",
        "\n",
        "# LOAD LABEL MAP DATA FOR PLOTTING\n",
        "\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "                                                                    use_display_name=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Detecting stenosis**"
      ],
      "metadata": {
        "id": "usm2ClcwMfJQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTWeVAvRPGIH"
      },
      "outputs": [],
      "source": [
        "# PROVIDE PATH TO IMAGE DIRECTORY\n",
        "IMAGE_PATHS = '/content/drive/MyDrive/workspace/stenosis_detection_FRCNN/images/test/14_007_10_0071.bmp'\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "\n",
        "print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n",
        "\n",
        "image = cv2.imread(IMAGE_PATHS)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image_expanded = np.expand_dims(image_rgb, axis=0)\n",
        "\n",
        "# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "input_tensor = tf.convert_to_tensor(image)\n",
        "# The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "# input_tensor = np.expand_dims(image_np, 0)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "# All outputs are batches tensors.\n",
        "# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "# We're only interested in the first num_detections.\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "               for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "image_with_detections = image.copy()\n",
        "\n",
        "# SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_with_detections,\n",
        "      detections['detection_boxes'],\n",
        "      detections['detection_classes'],\n",
        "      detections['detection_scores'],\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=1,\n",
        "      min_score_thresh=0.3,\n",
        "      agnostic_mode=False)\n",
        "\n",
        "print('Done')\n",
        "# DISPLAYS OUTPUT IMAGE\n",
        "imS = cv2.resize(image_with_detections, (720, 540))\n",
        "cv2_imshow(imS)\n",
        "# CLOSES WINDOW ONCE KEY IS PRESSED"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQIjm2C4xacA2uLiGknN76",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}